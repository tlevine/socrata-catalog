---
title: What file formats are on the data portals?
---
```{r configure, echo = F}
opts_chunk$set(fig.width=10, fig.height=5, dpi = 42 * 5)
```

While [at Socrata's office]() on Friday,
I learned of the [`/data.json`](https://data.oregon.gov/data.json) endpoint.
It contains an entry for each [dataset](),
uploaded by the data publisher; it doesn't contain all of the other
views that are based on these source datasets.
And it has [this format](http://project-open-data.github.io/schema/).

## How many datasets?
Socrata portals have [50,000 different views](), but only
`r nrow(datasets)` are original datasets, with a median of
`r median(table(datasets$portal))` datasets per portal.

```{r portal-counts, fig.width = 10, fig.height = 15}
p.portal.counts
```

### No derived datasets
This is much lower than my [earlier figure]()
because the present figure does not include [derived views]() (map, charts, &c.).

Some time, I'll compare the within-portal counts of original datasets
and derived datasets. But not right now.

### Federated data
It still includes [federated data]() (duplicates),
however, and this file doesn't make it easy to determine which direction
the federation is in. Some day, I'll look more at federation, probably by 
reading the federation information from home pages of the portals
or by following the links in the `/data.json` file.

### Cutoff at 1000?
I find it highly suspicious the following nine portals have exactly 1000
datasets and no portals have more than 1000.

```{r cutoff}
paste(names(sort(table(datasets$portal), decreasing = T)[1:9]), collapse = '\n')
```

Half of these portals federate `explore.data.gov`, which has quite a few datasets, and the JSON
files seem to just include some of the `explore.data.gov` data. I think these
files have only the first 1000 datasets, and I haven't figured out how to look
at the next pages, so I'll focus the present analysis on portals with fewer
than 1000 datasets.

## My curiousity about file formats
I've recently become curious about what formats the datasets come from. When
tabular data get loaded into a Socrata data portal, they get converted to a
tabular representation within the portal software. From that, they get converted
to a range of different tabular formats.

The Socrata data portal doesn't explicitly store the source format because of
how the import process works. Most of the data [probably come from Excel](scraperwiki),
and the data that aren't from Excel typically come from inside of a government
network where policies would make it inconvenient to expose the database to the
world. Because of this, Socrata doesn't query database servers. Instead, data
publishers write middlemen that act as both database clients and Socrata clients.
They query the database and then make [web requests](api)
to the Socrata portal.

## `/data.json` contains file format information
The `/data.json` endpoint contains a file format field per the Project Open Data
schema. This refers to the format of the data as served from the Socrata portal,
not the format it was stored in before it got to the Socrata portal. But this
still tells us something about the source file formats.

People sometimes upload things that Socrata doesn't interpret as tables. PDFs are
a major example. Other times, people upload or [link to]()
files that could be tables but don't specify that they are tables.

Data formats are represented in two fields, `format` and `distribution`. `distribution`
seems to contain all of the different available formats. If the data are imported as
tabular data, it contains CSV, JSON, XML, &c., all served from the Socrata site.
And if the data are external links, it will contain a few external links, still
specifying the file types. The `format` field contains one of the formats that are
specified in the `distribution` field. I think it's just the first of the formats.
For the present analysis, I'm using the `format` field.

(image of counts across portal)

And here are some of the main types by portal.

```{r all-formats, fig.width = 10, fig.height = 15}
p.all
```

`csv` mostly refers
to data that Socrata represents as a table; this is the sort of data that Socrata
can convert to a range of different tabular data formats.
It is also my [preferred file format](http://csvsoundsystem.com).

The other formats appear to be external links.

## CSV
Most datasets are CSV (`r sum(na.omit(datasets$format == 'csv'))' of `r nrow(datasets`).
I was curious as to how this varies by portal and over time, and the following image
addresses that. It contains one plot per data portal. The x-axis of each plot is the date,
the y-axis is the proportion[^proportion] of datasets that are tabular (CSV), and the
width of the line is the number of datasets on the portal.

For example, if there were 100 datasets on a portal in June 2011 and 80 were CSV, the
line would be near the top of the graph and quite skinny at June 2011.

```{r csv-cum-facet, fig.width = 20, fig.height = 10}
p.csv.cum.facet
```

## Some interesting portals
Some portals have only CSV data (like `data.medicare.gov`), but most contain
other data. I am curious both as to what other data formats they have and what
prompted the shifts in dataset format.

Missouri mostly has PDFs.

```{r mo}
p.data.mo.gov
```

Also interesting about Missouri is that it federates [Kansas City](https://data.kcmo.org/),
which didn't appear in my list of portals.

I know I said I'd focus on portals with fewer than 1000 datasets, but Lehman College is
interesting because it has lots of zipped files.

```{r lehman}
p.bronx.lehman.cuny.edu
```

San Francisco has a lot of CSVs, a lot of externally linked zip files,
and a lot of externally linked files of unknown format.

```{r sf}
p.data.sfgov.org
```

## Determination of external link file formats
It looks like the format of external links is determined by the file name.
For example, Edmonton's
[Road and Traffic Updates](https://data.edmonton.ca/Transportation/Road-and-Traffic-Updates/5ggc-prfp?)
are marked as `application/rss+xml` because the external link,
[http://www.trumba.com/calendars/construction-and-special-events-road-closures.rss](http://www.trumba.com/calendars/construction-and-special-events-road-closures.rss),
ends in `.rss`.

In contrast, the [Maryland Land Use/ Land Cover: 1973, 2002, 2010](https://data.maryland.gov/d/ywbg-ptfh)
dataset is marked as having the format `application/octet-stream` because the
external link, [http://planning.maryland.gov/OurWork/landUseDownload.shtml](http://planning.maryland.gov/OurWork/landUseDownload.shtml),
ends in `.shtml`.

<!-- sqldf("select title, 'https://' || portal || '/d/' || identifier AS portalURL, accessURL from catalog where identifier = 'ywbg-ptfh'", dbname = '/tmp/catalog.db') -->

## CSV, pdf, zip and octet-stream
Based on the examples above, it seems like a lot of datasets are PDF, zip or unknown
external links. I made the following series of plots to check it. It is just like the
[similar image above](#csv) except for the y-axes; instead of representing the
proportion of datasets that are CSV, each y-axis represents the proportion of datasets
that are CSV, PDF, zip or unknown external links.

```{r csv-pdf-zip-octet-cum-facet, fig.width = 20, fig.height = 10}
p.csv.pdf.zip.octet.cum.facet
```

Most of the curves are pretty straight and stay near 1, meaning that the proportion doesn't
change much and that the proportion is quite high. Thus, it looks like most datasets are
either CSV, pdf, zip or external links of unknown format.

## Dates of significant changes
A few portals have only CSV data since the beginning, but most have had other formats.
Looking at the plots, we can see dates where there was a sudden change in the proportion
of datasets that were CSV.

### Sudden changes at the beginning
When the first dataset gets uploaded, the proportion of datasets that are CSV is either
zero or one. Thus, the line for all of these datasets starts either at zero or one.
Most datasets sharply change after that; `data.austintexas.gov` and `data.mo.gov` are
examples.

Others stay at this level for quite a while because no datasets were uploaded for a
while. (Is that true?) `data.raleighnc.gov` is an example of this; its first dataset...
its next dataset...   `data.illinois.gov`

### Sudden changes after the beginning
`data.cityofchicago.gov`
`data.sfgov.org`


### Bursts of dataset upload
It's not the main point of the plots, but we can also how gradually or suddenly portals
uploaded their data.

`data.illinois.gov`
`data.sunlightlabs.com`

## More study of file formats
This got me thinking about other ways of studying file formats and other things.

### The attribution field
Socrata's SODA 1 API [contains]() an `attribution` field, which references the URL from
which the dataset was taken. (I presume that this is entered manually.) This would be one
way of figuring out the source format, or at least some related information about the source.

### Externally linked CSVs
Not all of the CSV-formatted datasets necessarily come from Socrata; some might be links
to external CSV files. There is enough information in `/data.json` to determine which of
these categories a CSV dataset falls into.

### Determining the formats of external links
It looks to me like the format type of external links is determined based on the file
extension of the URL; `octet-stream` datasets seem to correspond to URLs without file
extensions or with file extensions like `aspx` that don't clearly correspond to a
particular file types. One could determine the formats of these datasets by
downloading the files.

## Footnotes

[^proportion]: It's actually a tad bit more complicated than that. These dates are the
    creation dates of the datasets that are available today; I do not know about datasets
    that were historically on the portal and have since been deleted.
